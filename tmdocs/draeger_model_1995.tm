<TeXmacs|1.99.6>

<style|<tuple|generic|paperwhy|old-spacing>>

<\body>
  <\hide-preamble>
    \;

    <assign|by-text|<macro|>>
  </hide-preamble>

  <\doc-data|<doc-title|Model predictive control using neural
  networks>|<doc-author|<author-data|<author-name|Draeger,
  Andreas>>>|<doc-author|<author-data|<author-name|Engell,
  Sebastian>>>|<doc-author|<author-data|<author-name|Ranke, Horst>>>>
    \;
  </doc-data>

  <tags|predictive control|nonlinear control>

  <strong|tl;dr:> A small, shallow neural net is used as a nonlinear
  black-box model for predictive control of a laboratory device. Training is
  performed off-line with inputs and outputs measured during linearly
  controlled operation of the device. Some of the network hyperparameters are
  tuned during training via a genetic algorithm.

  <hrule>

  Developing nonlinear models for predictive control is difficult:
  principle-based approaches are complex and require lots of experimental
  validation, while sometimes the dynamics are just too complex for
  modelling.

  The goal is to approximate the dynamics with a neural network. One
  <strong|key insight> of the paper is that

  <\quotation>
    measurements of input/output variables of the plant operated with the
    linear controller may provide very good training data for the neural
    network. This approach is more practical (the plant is always under
    automatic control) and more effective (the excitation is much more
    similar to the one encountered under the final nonlinear control scheme)
    than using experiments without control (open-loop identification).
  </quotation>

  The device considered is a pH neutralisation reactor with two different
  solutions coming in, one of them at a fixed flow rate, the other being the
  single input <math|u> for the controller. The monitored output variable
  <math|y> is the pH of the reactor.

  <subsection|Model predictive control>

  At each sampling step an MPC computes a control action \Pby solving an
  open-loop optimal control problem over a finite prediction horizon\Q
  (<dfn|receding horizon strategy>). The steps are:

  <\enumerate>
    <item>Predict the vector of outputs <math|<wide|\<b-y\>|^><around*|(|t|)>=<around*|(|<wide|y|^><rsub|t+1>,\<ldots\>,<wide|y|^><rsub|t+n<rsub|p>>|)>>,
    which is a function both of internal states and the vector of future
    control variables <math|\<b-u\><around*|(|t|)>=<around*|(|u<rsub|t+1>,\<ldots\>,u<rsub|t+n<rsub|u>>|)>>.
    Here <math|n<rsub|p>> is the length of the <dfn|prediction horizon> and
    <math|n<rsub|u>> that of the <dfn|control horizon>.<\footnote>
      If <math|n<rsub|u>\<less\>n<rsub|p>> then
      <math|\<b-u\><around*|(|t|)>=<around*|(|u<rsub|t+1>,\<ldots\>,u<rsub|t+n<rsub|u>>,\<ldots\>,u<rsub|t+n<rsub|u>>|)>>.
    </footnote>

    <item>Compute the change in the control vector
    <math|\<Delta\>\<b-u\><around*|(|t|)>=\<b-u\><around*|(|t|)>-\<b-u\><around*|(|t-1|)>>
    to minimise a cost function including the error in the estimate for the
    controlled variable <strong|y>:

    <\equation*>
      J<around*|(|\<b-y\><around*|(|t|)>,\<b-u\><around*|(|t|)>|)>=<around*|\<\|\|\>|\<b-y\><around*|(|t|)>-<wide|\<b-y\>|^><around*|(|t|)>|\<\|\|\>><rsup|2><rsub|W>+<around*|\<\|\|\>|\<Delta\>\<b-u\><around*|(|t|)>|\<\|\|\>><rsub|V><rsup|2>.
    </equation*>

    <\todo>
      Clarify: how is <math|y> computed if it depends on <math|u> which is in
      <math|argmin J>?
    </todo>
  </enumerate>

  Prediction error is used for <todo|<dfn|disturbance estimation>>.

  A neural network <math|f> is used to approximate the response of the
  system. It has as 10 inputs the control values
  <math|u<rsub|t>,\<ldots\>,u<rsub|t-4>> and the outputs
  <math|y<rsub|t>,\<ldots\>,y<rsub|t-4>> and is trained to estimate the
  output <math|y<rsub|t+1>> for any <math|t>:

  <\equation*>
    f<around*|(|y<rsub|t>,\<ldots\>,y<rsub|t-4>,u<rsub|t>,\<ldots\>,u<rsub|t-4>|)>=<wide|y|^><rsub|t+1>.
  </equation*>

  <math|f> is applied recursively to predict all of
  <math|\<b-y\><around*|(|t|)>=<around*|(|y<rsub|t+1>,\<ldots\>,y<rsub|t+n<rsub|p>>|)>>.

  The activations of <math|f> are a type of sigmoid with slopes parameterised
  by scalars <math|\<sigma\>> (<todo|Fermi function>). These are optimised
  with a genetic algorithm which runs on small populations of networks
  trained with a form of adaptive momentum backpropagation (<todo|SuperSAB>):
  First a population is generated randomly. Then a new member is generated by
  genetic operators on a string encoding the activation slopes and trained
  for a while. If it performs better than the worst member of the existing
  population, it replaces the latter. This process of generating, training,
  replacing is repeated until \Pacceptable performance by the best member is
  achieved\Q. Because of the selection, training with bad hyperparemeter
  choices is avoided.

  Training is performed once on a historic dataset

  <\quotation>
    which is generated by the system under closed-loop control with a
    reasonable PI-controller (...) [The authors] changed the setpoint for the
    linear controller randomly during plant operation under control
  </quotation>

  Training data therefore remains in the ranges where control is desired.

  <\quotation>
    suitable time series of data can be extracted from normal operation data
    (as long as sufficiently frequent and sufficiently large setpoint changes
    are possible). The only requirement is that the measurements represent
    the region of interest of the state space and that enough excitation
    relative to the unmeasured disturbances is provided.
  </quotation>

  A potential issue is that rare events overwhelming the controller might
  drive it into regimes for which it had no training data and therefore will
  not be able to recover from. This suggests that it will be essential to
  have a fall-back mechanism.

  <subsection|Extended Dynamic Matrix Control>

  ...

  \;

  <\bibliography|bib|tm-plain|paperwhy.bib>
    <bib-list|0|>
  </bibliography>
</body>

<\initial>
  <\collection>
    <associate|preamble|false>
    <associate|save-aux|true>
  </collection>
</initial>

<\references>
  <\collection>
    <associate|auto-1|<tuple|1|?>>
    <associate|auto-2|<tuple|2|?>>
    <associate|auto-3|<tuple|2|?>>
    <associate|footnote-1|<tuple|1|?>>
    <associate|footnr-1|<tuple|1|?>>
  </collection>
</references>

<\auxiliary>
  <\collection>
    <\associate|toc>
      <with|par-left|<quote|1tab>|1<space|2spc>Model predictive control
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-1>>

      <vspace*|1fn><with|font-series|<quote|bold>|math-font-series|<quote|bold>|Bibliography>
      <datoms|<macro|x|<repeat|<arg|x>|<with|font-series|medium|<with|font-size|1|<space|0.2fn>.<space|0.2fn>>>>>|<htab|5mm>>
      <no-break><pageref|auto-2><vspace|0.5fn>
    </associate>
  </collection>
</auxiliary>